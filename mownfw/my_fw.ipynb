{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_fw.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2Bvi+1XKu0lppQmuHQkYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deethereal/NN/blob/main/mownfw/my_fw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMn2Af33ccer"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "class Tensor(object):\r\n",
        "  def __init__(self,  data, autograd=False,creators = None, creation_op = None, id =None):\r\n",
        "    self.data = np.array(data)\r\n",
        "    self.creation_op=creation_op  #как был создан этот тензор\r\n",
        "    self.creators=creators #родители этого тензора\r\n",
        "    self.grad=None\r\n",
        "    self.autograd=autograd\r\n",
        "    self.children={}\r\n",
        "    if (id is None):\r\n",
        "      id=np.random.randint(0,100000000)\r\n",
        "    self.id=id\r\n",
        "    if creators is not None:\r\n",
        "      for c in creators:\r\n",
        "        if (self.id not in c.children):\r\n",
        "          c.children[self.id]=1\r\n",
        "        else:\r\n",
        "          c.children[self.id]+=1\r\n",
        "  def all_children_grads_accounted_for(self):\r\n",
        "    for id, cnt in self.children.items():\r\n",
        "      if (cnt!=0):\r\n",
        "        return False\r\n",
        "    return True\r\n",
        "  def backward(self,grad, grad_origin=None):\r\n",
        "    if (self.autograd):\r\n",
        "      if grad is None:\r\n",
        "        grad=Tensor(np.ones_like(self.data))\r\n",
        "      if (grad_origin is not None):\r\n",
        "        if (self.children[grad_origin.id] ==0):\r\n",
        "          raise Exception ('cannot backpop more once')\r\n",
        "        else:\r\n",
        "          self.children[grad_origin.id]-=1\r\n",
        "      if self.grad is None:\r\n",
        "        self.grad=grad#Tensor(np.ones_like(self.data))\r\n",
        "      else:\r\n",
        "        self.grad+=grad\r\n",
        "      if (self.creators is not None and (self.all_children_grads_accounted_for() or grad_origin is None)):\r\n",
        "        if self.creation_op == \"add\":\r\n",
        "          self.creators[0].backward(grad) \r\n",
        "          self.creators[1].backward(grad)\r\n",
        "        if self.creation_op == \"sub\":\r\n",
        "          new =Tensor(self.grad.data)\r\n",
        "          self.creators[0].backward(new,self)\r\n",
        "          new =  Tensor(self.grad.__neg__().data)\r\n",
        "          self.creators[1].backward(new,self)\r\n",
        "        if self.creation_op == \"neg\":\r\n",
        "          self.creators[0].backward(self.grad.__neg__()) \r\n",
        "        if self.creation_op == \"mul\":\r\n",
        "          new=self.grad*self.creators[1]\r\n",
        "          self.creators[0].backward(new,self) \r\n",
        "          new=self.grad*self.creators[0]\r\n",
        "          self.creators[1].backward(new,self)\r\n",
        "        if self.creation_op == \"mm\":\r\n",
        "          act=self.creators[0]\r\n",
        "          weights=self.creators[1]\r\n",
        "          new = self.grad.mm(weights.transpose())\r\n",
        "          act.backward(new)\r\n",
        "          new=self.grad.transpose().mm(act).transpose()\r\n",
        "          weights.backward(new)\r\n",
        "        if self.creation_op == \"transpose\":\r\n",
        "          self.creators[0].backward(self.grad.transpose())\r\n",
        "        if ('sum' in self.creation_op):\r\n",
        "          dim=int(self.creation_op.split('_')[1])\r\n",
        "          ds=self.creators[0].data.shape[dim]\r\n",
        "          self.creators[0].backward(self.grad.expand(dim,ds))\r\n",
        "        if ('expand' in self.creation_op):\r\n",
        "          dim=int(self.creation_op.split('_')[1])\r\n",
        "          self.creators[0].backward(self.grad.sum(dim))\r\n",
        "        if self.creation_op == 'tanh':\r\n",
        "          ones = Tensor(np.ones_like(self.grad.data))\r\n",
        "          self.creators[0].backward(self.grad*(ones-(self*self)))\r\n",
        "        if self.creation_op == 'sigmoid':\r\n",
        "          ones = Tensor(np.ones_like(self.grad.data))\r\n",
        "          self.creators[0].backward(self.grad*(self*(ones-self)))\r\n",
        "\r\n",
        "  def __add__(self,other):\r\n",
        "    if self.autograd and other.autograd:\r\n",
        "      return Tensor(self.data+other.data, autograd=True, creators=[self,other],creation_op='add')\r\n",
        "    return Tensor(self.data+other.data)\r\n",
        "  def __neg__(self):\r\n",
        "    if self.autograd:\r\n",
        "      return Tensor(self.data*-1, autograd=True, creators=[self],creation_op='neg')\r\n",
        "    return Tensor(self.data*-1)\r\n",
        "  def __sub__(self,other):\r\n",
        "    if(self.autograd and other.autograd):\r\n",
        "      return Tensor(self.data-other.data,autograd=True,creators=[self,other],creation_op='sub')\r\n",
        "    return Tensor(self.data-other.data)\r\n",
        "  def __mul__(self,other):\r\n",
        "    if(self.autograd and other.autograd):\r\n",
        "      return Tensor(self.data*other.data,autograd=True,creators=[self,other],creation_op='mul')\r\n",
        "    return Tensor(self.data*other.data)\r\n",
        "  def sum(self,dim):\r\n",
        "    if(self.autograd):\r\n",
        "      return Tensor(self.data.sum(dim),autograd=True,creators=[self],creation_op='sum_'+str(dim))\r\n",
        "    return Tensor(self.data.sum(dim))\r\n",
        "  def expand(self,dim,copies):\r\n",
        "    trans_cmd = list(range(0,len(self.data.shape)))\r\n",
        "    trans_cmd.insert(dim,len(self.data.shape))\r\n",
        "    new_shape=list(self.data.shape) + [copies]\r\n",
        "    new_data = self.data.repeat(copies).reshape(new_shape)\r\n",
        "    new_data = new_data.transpose(trans_cmd)\r\n",
        "    if (self.autograd):\r\n",
        "      return Tensor(new_data,autograd=True,creators=[self],creation_op='expand_'+str(dim))\r\n",
        "    return Tensor(new_data)\r\n",
        "  def transpose(self):\r\n",
        "    if (self.autograd):\r\n",
        "      return Tensor(self.data.transpose(),autograd=True,creators=[self],creation_op='transpose')\r\n",
        "    return Tensor(self.data.transpose())\r\n",
        "  def mm(self,x):\r\n",
        "    if (self.autograd):\r\n",
        "      return Tensor(self.data.dot(x.data),autograd=True,creators=[self,x],creation_op='mm')\r\n",
        "    return Tensor(self.data.dot(x.data))\r\n",
        "  def tanh(self):\r\n",
        "    if self.autograd:\r\n",
        "      return Tensor(np.tanh(self.data),autograd=True,creators=[self],creation_op='tanh')\r\n",
        "    return Tensor(np.tanh(self.data))\r\n",
        "  def sigmoid(self):\r\n",
        "    if self.autograd:\r\n",
        "      return Tensor(1/(1+np.exp(-self.data)),autograd=True,creators=[self],creation_op='sigmoid')\r\n",
        "    return Tensor(1/(1+np.exp(-self.data)))\r\n",
        "#Добавить в backward новые функции\r\n",
        "  def __repr__(self):\r\n",
        "    return str(self.data.__repr__())\r\n",
        "  def __str__(self):\r\n",
        "    return str(self.data.__str__())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYFN6A1m-iFb",
        "outputId": "c7f8f4ab-c197-449c-eac9-9c5e5c8685b4"
      },
      "source": [
        "a=Tensor([1,2,3,4,5],autograd=True)\n",
        "b=Tensor([2,2,2,2,2],autograd=True)\n",
        "c=Tensor([5,4,3,2,1],autograd=True)\n",
        "d=a+(-b)\n",
        "e=(-b)+c\n",
        "f=d+e\n",
        "f.backward(Tensor(np.array([1,1,1,1,1])))\n",
        "print(b.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2 -2 -2 -2 -2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrtB2NEU-mjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a1d7e2-8d17-49a2-ef55-2804643f305f"
      },
      "source": [
        "np.random.seed(0)\n",
        "data=Tensor(np.array([[0,0],[0,1],[1,0],[1,1]]),autograd=True)\n",
        "target=Tensor(np.array([[0],[1],[0],[1]]),autograd=True)\n",
        "w=list()\n",
        "\n",
        "w.append(Tensor(np.random.rand(2,3),autograd=True))\n",
        "w.append(Tensor(np.random.rand(3,1),autograd=True))\n",
        "for _ in range(20):\n",
        "  pred=data.mm(w[0]).mm(w[1])\n",
        "  loss = ((pred-target)*(pred-target)).sum(0)\n",
        "  loss.backward(Tensor(np.ones_like(loss.data)))\n",
        "  for ws in w:\n",
        "    ws.data -= ws.grad.data*0.1\n",
        "    ws.grad.data*=0.1\n",
        "  print(loss)\n",
        "               "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.6973519]\n",
            "[0.77451661]\n",
            "[0.25897421]\n",
            "[0.16823606]\n",
            "[0.11731015]\n",
            "[0.08220394]\n",
            "[0.05619558]\n",
            "[0.03747485]\n",
            "[0.0243653]\n",
            "[0.01546837]\n",
            "[0.00960953]\n",
            "[0.00585708]\n",
            "[0.00351226]\n",
            "[0.00207778]\n",
            "[0.00121564]\n",
            "[0.00070495]\n",
            "[0.00040594]\n",
            "[0.00023248]\n",
            "[0.00013258]\n",
            "[7.53627889e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0A6PmklcJ5e"
      },
      "source": [
        "#стохастический градиентный спуск\n",
        "class SGD(object):\n",
        "  def __init__(self, parameters, alpha):\n",
        "    self.parameters = parameters\n",
        "    self.alpha = alpha\n",
        "  def zero(self):\n",
        "    for p in self.parameters:\n",
        "      p.grad.data*=0\n",
        "  def step(self,zero=True):\n",
        "    for p in self.parameters:\n",
        "      p.data -=  p.grad.data*self.alpha\n",
        "      if zero:\n",
        "        p.grad.data*=0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHtDNm0OpQrA",
        "outputId": "e92a5b11-0e43-4c20-f730-e95912df8dbb"
      },
      "source": [
        "np.random.seed(0)\n",
        "data=Tensor(np.array([[0,0],[0,1],[1,0],[1,1]]),autograd=True)\n",
        "target=Tensor(np.array([[0],[1],[0],[1]]),autograd=True)\n",
        "w=list()\n",
        "\n",
        "w.append(Tensor(np.random.rand(2,3),autograd=True))\n",
        "w.append(Tensor(np.random.rand(3,1),autograd=True))\n",
        "optim=SGD(parameters=w, alpha=0.1)\n",
        "\n",
        "for _ in range(20):\n",
        "  pred=data.mm(w[0]).mm(w[1])\n",
        "  loss = ((pred-target)*(pred-target)).sum(0)\n",
        "  loss.backward(Tensor(np.ones_like(loss.data)))\n",
        "  optim.step()\n",
        "  print(loss)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.6973519]\n",
            "[0.77451661]\n",
            "[0.23280793]\n",
            "[0.17652952]\n",
            "[0.13235231]\n",
            "[0.09761048]\n",
            "[0.07068221]\n",
            "[0.05021296]\n",
            "[0.03499648]\n",
            "[0.02394675]\n",
            "[0.0161073]\n",
            "[0.01066715]\n",
            "[0.0069679]\n",
            "[0.00449764]\n",
            "[0.0028739]\n",
            "[0.00182086]\n",
            "[0.00114563]\n",
            "[0.00071668]\n",
            "[0.00044626]\n",
            "[0.00027685]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjPtyXnhpfgv"
      },
      "source": [
        "class Layer(object):\n",
        "  def __init__(self):\n",
        "    self.parameters = list()\n",
        "  def get_parameters(self):\n",
        "    return self.parameters\n",
        "class Linear(Layer):\n",
        "  def __init__(self, n_inputs, n_outputs):\n",
        "    super().__init__()\n",
        "    W=np.random.rand(n_inputs,n_outputs)*np.sqrt(2.0/(n_inputs))\n",
        "    self.weight=Tensor(W, autograd = True)\n",
        "    self.bias = Tensor(np.zeros(n_outputs),autograd=True)\n",
        "\n",
        "    self.parameters.append(self.weight)\n",
        "    self.parameters.append(self.bias)\n",
        "  def forward(self,input):\n",
        "    return input.mm(self.weight)+self.bias.expand(0,len(input.data))\n",
        "class Sequential(Layer):\n",
        "  def __init__(self, layers=list()):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "  def add(self,layer):\n",
        "    self.layers.append(layer)\n",
        "  def forward(self, input):\n",
        "    for layer in self.layers:\n",
        "      input = layer.forward(input)\n",
        "    return input\n",
        "  def get_parameters(self):\n",
        "    params=list()\n",
        "    for layer in self.layers:\n",
        "      params+=layer.get_parameters()\n",
        "    return params"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2h21CsswbfU",
        "outputId": "b58cc577-d1f5-4b4b-9293-b567c44c490a"
      },
      "source": [
        "np.random.seed(0)\n",
        "data=Tensor(np.array([[0,0],[0,1],[1,0],[1,1]]),autograd=True)\n",
        "target=Tensor(np.array([[0],[1],[0],[1]]),autograd=True)\n",
        "w=list()\n",
        "model = Sequential([Linear(2,3),Linear(3,1)])\n",
        "optim=SGD(parameters=model.get_parameters(), alpha=0.1)\n",
        "for _ in range(20):\n",
        "  pred=model.forward(data)\n",
        "  loss = ((pred-target)*(pred-target)).sum(0)\n",
        "  loss.backward(Tensor(np.ones_like(loss.data)))\n",
        "  optim.step()\n",
        "  print(loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.02081598]\n",
            "[0.45745883]\n",
            "[0.35185626]\n",
            "[0.31271478]\n",
            "[0.27911455]\n",
            "[0.24952852]\n",
            "[0.22324195]\n",
            "[0.19974467]\n",
            "[0.17865581]\n",
            "[0.15968257]\n",
            "[0.14259268]\n",
            "[0.12719581]\n",
            "[0.11333103]\n",
            "[0.10085831]\n",
            "[0.08965292]\n",
            "[0.07960175]\n",
            "[0.07060096]\n",
            "[0.06255451]\n",
            "[0.0553733]\n",
            "[0.04897462]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlPcbDsGwp8F"
      },
      "source": [
        "class MSELoss(Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def forward(self, pred, target):\n",
        "    return ((pred-target)*(pred-target)).sum(0)\n",
        "class Tanh(Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def forward(self,input):\n",
        "    return input.tanh()\n",
        "class Sigmoid(Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def forward(self,input):\n",
        "    return input.sigmoid()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzwpYRaQytU5",
        "outputId": "447382f6-68a9-449a-d181-ca47897e9724"
      },
      "source": [
        "np.random.seed(0)\n",
        "data=Tensor(np.array([[0,0],[0,1],[1,0],[1,1]]),autograd=True)\n",
        "target=Tensor(np.array([[0],[1],[0],[1]]),autograd=True)\n",
        "w=list()\n",
        "model = Sequential([Linear(2,3),Tanh(),Linear(3,1),Sigmoid()])\n",
        "criterion = MSELoss()\n",
        "optim=SGD(parameters=model.get_parameters(), alpha=1)\n",
        "for _ in range(10):\n",
        "  pred=model.forward(data)\n",
        "  loss = criterion.forward(pred,target)\n",
        "  loss.backward(Tensor(np.ones_like(loss.data)))\n",
        "  optim.step()\n",
        "  print(loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.85110375]\n",
            "[0.66019917]\n",
            "[0.4741872]\n",
            "[0.28951316]\n",
            "[0.16696756]\n",
            "[0.10468702]\n",
            "[0.07262803]\n",
            "[0.05433666]\n",
            "[0.0428526]\n",
            "[0.0350933]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-xxsunn3O3w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}